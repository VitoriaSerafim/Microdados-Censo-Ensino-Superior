{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre- requisitos para executar o notebook\n",
    "pip install pandas numpy matplotlib seaborn jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de Qualidade de Dados - Crit√©rios DMBOK\n",
    "# An√°lise de 5 CSVs (um para cada ano) seguindo os crit√©rios do DAMA-DMBOK\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMBOKDataQualityAnalyzer:\n",
    "    \"\"\"\n",
    "    Analisador de Qualidade de Dados baseado nos crit√©rios do DAMA-DMBOK\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dataframes = {}\n",
    "        self.quality_report = {}\n",
    "        self.years = []\n",
    "    \n",
    "    def load_csvs(self, file_paths):\n",
    "        \"\"\"\n",
    "        Carrega os CSVs para an√°lise\n",
    "        file_paths: lista de caminhos dos arquivos CSV\n",
    "        \"\"\"\n",
    "        for i, path in enumerate(file_paths):\n",
    "            year = 2019 + i  # Assumindo anos de 2019 a 2023\n",
    "            try:\n",
    "                df = pd.read_csv(path, encoding='utf-8')\n",
    "                self.dataframes[year] = df\n",
    "                self.years.append(year)\n",
    "                print(f\"‚úì CSV {year} carregado: {len(df)} registros, {len(df.columns)} colunas\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó Erro ao carregar CSV {year}: {e}\")\n",
    "    \n",
    "    def analyze_completeness(self):\n",
    "        \"\"\"\n",
    "        Crit√©rio DMBOK: Completude (Completeness)\n",
    "        Analisa dados ausentes, nulos e vazios\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"AN√ÅLISE DE COMPLETUDE (COMPLETENESS)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        completeness_data = []\n",
    "        \n",
    "        for year, df in self.dataframes.items():\n",
    "            print(f\"\\nüìä Ano {year}:\")\n",
    "            \n",
    "            # An√°lise por coluna\n",
    "            missing_analysis = {}\n",
    "            for col in df.columns:\n",
    "                total_records = len(df)\n",
    "                missing_count = df[col].isnull().sum()\n",
    "                empty_strings = (df[col] == '').sum() if df[col].dtype == 'object' else 0\n",
    "                total_missing = missing_count + empty_strings\n",
    "                completeness_pct = ((total_records - total_missing) / total_records) * 100\n",
    "                \n",
    "                missing_analysis[col] = {\n",
    "                    'total_records': total_records,\n",
    "                    'missing_values': missing_count,\n",
    "                    'empty_strings': empty_strings,\n",
    "                    'total_incomplete': total_missing,\n",
    "                    'completeness_percentage': completeness_pct\n",
    "                }\n",
    "                \n",
    "                print(f\"  {col}: {completeness_pct:.1f}% completo ({total_missing} valores incompletos)\")\n",
    "            \n",
    "            # Completude geral do dataset\n",
    "            overall_completeness = df.count().sum() / (len(df) * len(df.columns)) * 100\n",
    "            print(f\"\\n  üìà Completude Geral: {overall_completeness:.1f}%\")\n",
    "            \n",
    "            completeness_data.append({\n",
    "                'year': year,\n",
    "                'overall_completeness': overall_completeness,\n",
    "                'column_analysis': missing_analysis\n",
    "            })\n",
    "        \n",
    "        self.quality_report['completeness'] = completeness_data\n",
    "    \n",
    "    def analyze_consistency(self):\n",
    "        \"\"\"\n",
    "        Crit√©rio DMBOK: Consist√™ncia (Consistency)\n",
    "        Analisa padr√µes de dados entre anos e dentro de datasets\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"AN√ÅLISE DE CONSIST√äNCIA (CONSISTENCY)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        consistency_data = []\n",
    "        \n",
    "        # 1. Consist√™ncia estrutural (colunas)\n",
    "        print(\"\\nüîç Consist√™ncia Estrutural:\")\n",
    "        all_columns = set()\n",
    "        column_presence = {}\n",
    "        \n",
    "        for year, df in self.dataframes.items():\n",
    "            cols = set(df.columns)\n",
    "            all_columns.update(cols)\n",
    "            column_presence[year] = cols\n",
    "        \n",
    "        # Verificar se todas as colunas est√£o presentes em todos os anos\n",
    "        consistent_columns = all_columns.copy()\n",
    "        for col in all_columns:\n",
    "            years_present = [year for year, cols in column_presence.items() if col in cols]\n",
    "            if len(years_present) != len(self.years):\n",
    "                print(f\"  ‚ö†Ô∏è  Coluna '{col}' ausente em: {set(self.years) - set(years_present)}\")\n",
    "                consistent_columns.discard(col)\n",
    "        \n",
    "        structural_consistency = len(consistent_columns) / len(all_columns) * 100\n",
    "        print(f\"  üìä Consist√™ncia Estrutural: {structural_consistency:.1f}%\")\n",
    "        \n",
    "        # 2. Consist√™ncia de tipos de dados\n",
    "        print(\"\\nüîç Consist√™ncia de Tipos:\")\n",
    "        type_consistency = {}\n",
    "        \n",
    "        for col in consistent_columns:\n",
    "            types_per_year = {}\n",
    "            for year, df in self.dataframes.items():\n",
    "                if col in df.columns:\n",
    "                    types_per_year[year] = str(df[col].dtype)\n",
    "            \n",
    "            unique_types = set(types_per_year.values())\n",
    "            is_consistent = len(unique_types) == 1\n",
    "            type_consistency[col] = {\n",
    "                'consistent': is_consistent,\n",
    "                'types_by_year': types_per_year\n",
    "            }\n",
    "            \n",
    "            if not is_consistent:\n",
    "                print(f\"  ‚ö†Ô∏è  '{col}': Tipos inconsistentes - {types_per_year}\")\n",
    "        \n",
    "        # 3. Consist√™ncia de categorias (para campos categ√≥ricos)\n",
    "        print(\"\\nüîç Consist√™ncia de Categorias:\")\n",
    "        category_consistency = {}\n",
    "        \n",
    "        for col in consistent_columns:\n",
    "            if any(df[col].dtype == 'object' for year, df in self.dataframes.items() if col in df.columns):\n",
    "                categories_per_year = {}\n",
    "                for year, df in self.dataframes.items():\n",
    "                    if col in df.columns:\n",
    "                        categories_per_year[year] = set(df[col].dropna().unique())\n",
    "                \n",
    "                # Verificar se as categorias s√£o consistentes\n",
    "                all_categories = set()\n",
    "                for cats in categories_per_year.values():\n",
    "                    all_categories.update(cats)\n",
    "                \n",
    "                consistent_categories = all_categories.copy()\n",
    "                for cat in all_categories:\n",
    "                    years_with_cat = [year for year, cats in categories_per_year.items() if cat in cats]\n",
    "                    if len(years_with_cat) < len(self.years) * 0.8:  # Presente em pelo menos 80% dos anos\n",
    "                        consistent_categories.discard(cat)\n",
    "                \n",
    "                category_consistency[col] = {\n",
    "                    'total_categories': len(all_categories),\n",
    "                    'consistent_categories': len(consistent_categories),\n",
    "                    'consistency_percentage': len(consistent_categories) / len(all_categories) * 100 if all_categories else 100\n",
    "                }\n",
    "                \n",
    "                print(f\"  {col}: {category_consistency[col]['consistency_percentage']:.1f}% das categorias consistentes\")\n",
    "        \n",
    "        consistency_data.append({\n",
    "            'structural_consistency': structural_consistency,\n",
    "            'type_consistency': type_consistency,\n",
    "            'category_consistency': category_consistency\n",
    "        })\n",
    "        \n",
    "        self.quality_report['consistency'] = consistency_data\n",
    "    \n",
    "    def analyze_accuracy(self):\n",
    "        \"\"\"\n",
    "        Crit√©rio DMBOK: Precis√£o/Acur√°cia (Accuracy)\n",
    "        Analisa valores v√°lidos baseados nas regras de neg√≥cio\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"AN√ÅLISE DE PRECIS√ÉO/ACUR√ÅCIA (ACCURACY)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        accuracy_data = []\n",
    "        \n",
    "        for year, df in self.dataframes.items():\n",
    "            print(f\"\\nüìä Ano {year}:\")\n",
    "            year_accuracy = {}\n",
    "            \n",
    "            for col in df.columns:\n",
    "                col_accuracy = {'valid_values': 0, 'invalid_values': 0, 'accuracy_percentage': 0}\n",
    "                \n",
    "                # An√°lise espec√≠fica por tipo de coluna\n",
    "                if 'TIPO' in col.upper() or 'TP_' in col:\n",
    "                    # Campos categ√≥ricos - verificar se seguem padr√£o num√©rico esperado\n",
    "                    valid_values = df[col].dropna()\n",
    "                    if valid_values.dtype in ['int64', 'float64']:\n",
    "                        # Assumindo que c√≥digos v√°lidos s√£o n√∫meros positivos\n",
    "                        valid_count = (valid_values > 0).sum()\n",
    "                        invalid_count = len(valid_values) - valid_count\n",
    "                    else:\n",
    "                        # Para strings, verificar se n√£o est√£o vazias\n",
    "                        valid_count = (valid_values != '').sum()\n",
    "                        invalid_count = (valid_values == '').sum()\n",
    "                    \n",
    "                    col_accuracy = {\n",
    "                        'valid_values': valid_count,\n",
    "                        'invalid_values': invalid_count,\n",
    "                        'accuracy_percentage': (valid_count / len(valid_values)) * 100 if len(valid_values) > 0 else 0\n",
    "                    }\n",
    "                \n",
    "                elif 'TAMANHO' in col.upper():\n",
    "                    # Campo tamanho - deve ser num√©rico positivo\n",
    "                    valid_values = df[col].dropna()\n",
    "                    if len(valid_values) > 0:\n",
    "                        try:\n",
    "                            numeric_values = pd.to_numeric(valid_values, errors='coerce')\n",
    "                            valid_count = (numeric_values > 0).sum()\n",
    "                            invalid_count = len(valid_values) - valid_count\n",
    "                            col_accuracy = {\n",
    "                                'valid_values': valid_count,\n",
    "                                'invalid_values': invalid_count,\n",
    "                                'accuracy_percentage': (valid_count / len(valid_values)) * 100\n",
    "                            }\n",
    "                        except:\n",
    "                            col_accuracy['accuracy_percentage'] = 0\n",
    "                \n",
    "                else:\n",
    "                    # Para outros campos, verificar apenas se n√£o s√£o nulos/vazios\n",
    "                    valid_values = df[col].dropna()\n",
    "                    if df[col].dtype == 'object':\n",
    "                        valid_count = (valid_values != '').sum()\n",
    "                        invalid_count = (valid_values == '').sum()\n",
    "                    else:\n",
    "                        valid_count = len(valid_values)\n",
    "                        invalid_count = 0\n",
    "                    \n",
    "                    col_accuracy = {\n",
    "                        'valid_values': valid_count,\n",
    "                        'invalid_values': invalid_count,\n",
    "                        'accuracy_percentage': (valid_count / len(valid_values)) * 100 if len(valid_values) > 0 else 0\n",
    "                    }\n",
    "                \n",
    "                year_accuracy[col] = col_accuracy\n",
    "                print(f\"  {col}: {col_accuracy['accuracy_percentage']:.1f}% preciso\")\n",
    "            \n",
    "            # Precis√£o geral do ano\n",
    "            overall_accuracy = np.mean([acc['accuracy_percentage'] for acc in year_accuracy.values()])\n",
    "            print(f\"\\n  üìà Precis√£o Geral: {overall_accuracy:.1f}%\")\n",
    "            \n",
    "            accuracy_data.append({\n",
    "                'year': year,\n",
    "                'overall_accuracy': overall_accuracy,\n",
    "                'column_accuracy': year_accuracy\n",
    "            })\n",
    "        \n",
    "        self.quality_report['accuracy'] = accuracy_data\n",
    "    \n",
    "    def analyze_validity(self):\n",
    "        \"\"\"\n",
    "        Crit√©rio DMBOK: Validade (Validity)\n",
    "        Verifica se os dados seguem formatos e regras esperados\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"AN√ÅLISE DE VALIDADE (VALIDITY)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        validity_data = []\n",
    "        \n",
    "        for year, df in self.dataframes.items():\n",
    "            print(f\"\\nüìä Ano {year}:\")\n",
    "            year_validity = {}\n",
    "            \n",
    "            for col in df.columns:\n",
    "                validity_issues = []\n",
    "                valid_count = 0\n",
    "                total_count = len(df[col].dropna())\n",
    "                \n",
    "                if total_count == 0:\n",
    "                    year_validity[col] = {'validity_percentage': 0, 'issues': ['Coluna vazia']}\n",
    "                    continue\n",
    "                \n",
    "                # Verifica√ß√µes espec√≠ficas por tipo de campo\n",
    "                if 'NOME' in col.upper() or 'DESCRICAO' in col.upper():\n",
    "                    # Campos de texto - verificar comprimento m√≠nimo\n",
    "                    valid_values = df[col].dropna()\n",
    "                    valid_count = (valid_values.str.len() >= 3).sum()\n",
    "                    if valid_count < total_count:\n",
    "                        validity_issues.append(f\"{total_count - valid_count} valores com menos de 3 caracteres\")\n",
    "                \n",
    "                elif 'TIPO' in col.upper() or 'TP_' in col:\n",
    "                    # Campos categ√≥ricos - verificar se s√£o n√∫meros ou seguem padr√£o\n",
    "                    valid_values = df[col].dropna()\n",
    "                    if valid_values.dtype == 'object':\n",
    "                        # Verificar se seguem padr√£o \"N. Descri√ß√£o\"\n",
    "                        pattern_matches = valid_values.str.match(r'^\\d+\\..*').sum()\n",
    "                        valid_count = pattern_matches\n",
    "                        if pattern_matches < total_count:\n",
    "                            validity_issues.append(f\"{total_count - pattern_matches} valores n√£o seguem padr√£o 'N. Descri√ß√£o'\")\n",
    "                    else:\n",
    "                        # Para num√©ricos, verificar se s√£o inteiros positivos\n",
    "                        valid_count = ((valid_values > 0) & (valid_values % 1 == 0)).sum()\n",
    "                        if valid_count < total_count:\n",
    "                            validity_issues.append(f\"{total_count - valid_count} valores n√£o s√£o inteiros positivos\")\n",
    "                \n",
    "                elif 'TAMANHO' in col.upper():\n",
    "                    # Campo tamanho - deve ser num√©rico\n",
    "                    valid_values = df[col].dropna()\n",
    "                    try:\n",
    "                        numeric_values = pd.to_numeric(valid_values, errors='coerce')\n",
    "                        valid_count = (~numeric_values.isna()).sum()\n",
    "                        if valid_count < total_count:\n",
    "                            validity_issues.append(f\"{total_count - valid_count} valores n√£o num√©ricos\")\n",
    "                    except:\n",
    "                        validity_issues.append(\"Erro na convers√£o para num√©rico\")\n",
    "                        valid_count = 0\n",
    "                \n",
    "                elif 'CATEGORIA' in col.upper():\n",
    "                    # Campo categoria - verificar formato estruturado\n",
    "                    valid_values = df[col].dropna()\n",
    "                    # Assumir que categorias v√°lidas t√™m pelo menos uma numera√ß√£o\n",
    "                    pattern_matches = valid_values.str.contains(r'\\d+\\.', na=False).sum()\n",
    "                    valid_count = pattern_matches\n",
    "                    if pattern_matches < total_count:\n",
    "                        validity_issues.append(f\"{total_count - pattern_matches} categorias sem numera√ß√£o\")\n",
    "                \n",
    "                else:\n",
    "                    # Para outros campos, assumir v√°lidos se n√£o est√£o vazios\n",
    "                    valid_count = total_count\n",
    "                \n",
    "                validity_percentage = (valid_count / total_count) * 100 if total_count > 0 else 0\n",
    "                year_validity[col] = {\n",
    "                    'validity_percentage': validity_percentage,\n",
    "                    'issues': validity_issues\n",
    "                }\n",
    "                \n",
    "                print(f\"  {col}: {validity_percentage:.1f}% v√°lido\")\n",
    "                if validity_issues:\n",
    "                    for issue in validity_issues:\n",
    "                        print(f\"    ‚ö†Ô∏è  {issue}\")\n",
    "            \n",
    "            # Validade geral do ano\n",
    "            overall_validity = np.mean([val['validity_percentage'] for val in year_validity.values()])\n",
    "            print(f\"\\n  üìà Validade Geral: {overall_validity:.1f}%\")\n",
    "            \n",
    "            validity_data.append({\n",
    "                'year': year,\n",
    "                'overall_validity': overall_validity,\n",
    "                'column_validity': year_validity\n",
    "            })\n",
    "        \n",
    "        self.quality_report['validity'] = validity_data\n",
    "    \n",
    "    def analyze_timeliness(self):\n",
    "        \"\"\"\n",
    "        Crit√©rio DMBOK: Atualidade (Timeliness)\n",
    "        Analisa se os dados est√£o atualizados e relevantes\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"AN√ÅLISE DE ATUALIDADE (TIMELINESS)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Verificar se temos dados para anos consecutivos\n",
    "        years_sorted = sorted(self.years)\n",
    "        expected_years = list(range(min(years_sorted), max(years_sorted) + 1))\n",
    "        missing_years = set(expected_years) - set(years_sorted)\n",
    "        \n",
    "        print(f\"üìÖ Anos dispon√≠veis: {years_sorted}\")\n",
    "        if missing_years:\n",
    "            print(f\"‚ö†Ô∏è  Anos ausentes: {sorted(missing_years)}\")\n",
    "        \n",
    "        # Calcular atualidade baseada na cobertura temporal\n",
    "        temporal_coverage = len(years_sorted) / len(expected_years) * 100\n",
    "        print(f\"üìä Cobertura Temporal: {temporal_coverage:.1f}%\")\n",
    "        \n",
    "        # Verificar se os dados mais recentes s√£o do ano atual ou pr√≥ximo\n",
    "        current_year = 2025  # Ajustar conforme necess√°rio\n",
    "        most_recent_year = max(years_sorted)\n",
    "        years_behind = current_year - most_recent_year\n",
    "        \n",
    "        timeliness_score = max(0, 100 - (years_behind * 20))  # Penalizar 20% por ano de atraso\n",
    "        print(f\"üìà Score de Atualidade: {timeliness_score:.1f}% (dados mais recentes: {most_recent_year})\")\n",
    "        \n",
    "        self.quality_report['timeliness'] = {\n",
    "            'temporal_coverage': temporal_coverage,\n",
    "            'most_recent_year': most_recent_year,\n",
    "            'years_behind': years_behind,\n",
    "            'timeliness_score': timeliness_score\n",
    "        }\n",
    "    \n",
    "    def generate_visualizations(self):\n",
    "        \"\"\"\n",
    "        Gera visualiza√ß√µes dos resultados da an√°lise\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"GERANDO VISUALIZA√á√ïES\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle('An√°lise de Qualidade de Dados - Crit√©rios DMBOK', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. Completude por ano\n",
    "        if 'completeness' in self.quality_report:\n",
    "            years = [item['year'] for item in self.quality_report['completeness']]\n",
    "            completeness = [item['overall_completeness'] for item in self.quality_report['completeness']]\n",
    "            \n",
    "            axes[0, 0].plot(years, completeness, marker='o', linewidth=2, markersize=8)\n",
    "            axes[0, 0].set_title('Completude por Ano', fontweight='bold')\n",
    "            axes[0, 0].set_xlabel('Ano')\n",
    "            axes[0, 0].set_ylabel('Completude (%)')\n",
    "            axes[0, 0].grid(True, alpha=0.3)\n",
    "            axes[0, 0].set_ylim(0, 100)\n",
    "        \n",
    "        # 2. Precis√£o por ano\n",
    "        if 'accuracy' in self.quality_report:\n",
    "            years = [item['year'] for item in self.quality_report['accuracy']]\n",
    "            accuracy = [item['overall_accuracy'] for item in self.quality_report['accuracy']]\n",
    "            \n",
    "            axes[0, 1].plot(years, accuracy, marker='s', linewidth=2, markersize=8, color='orange')\n",
    "            axes[0, 1].set_title('Precis√£o por Ano', fontweight='bold')\n",
    "            axes[0, 1].set_xlabel('Ano')\n",
    "            axes[0, 1].set_ylabel('Precis√£o (%)')\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "            axes[0, 1].set_ylim(0, 100)\n",
    "        \n",
    "        # 3. Validade por ano\n",
    "        if 'validity' in self.quality_report:\n",
    "            years = [item['year'] for item in self.quality_report['validity']]\n",
    "            validity = [item['overall_validity'] for item in self.quality_report['validity']]\n",
    "            \n",
    "            axes[1, 0].plot(years, validity, marker='^', linewidth=2, markersize=8, color='green')\n",
    "            axes[1, 0].set_title('Validade por Ano', fontweight='bold')\n",
    "            axes[1, 0].set_xlabel('Ano')\n",
    "            axes[1, 0].set_ylabel('Validade (%)')\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "            axes[1, 0].set_ylim(0, 100)\n",
    "        \n",
    "        # 4. Resumo geral de qualidade\n",
    "        if all(key in self.quality_report for key in ['completeness', 'accuracy', 'validity']):\n",
    "            metrics = ['Completude', 'Precis√£o', 'Validade']\n",
    "            scores = []\n",
    "            \n",
    "            # Calcular m√©dia de cada m√©trica\n",
    "            completeness_avg = np.mean([item['overall_completeness'] for item in self.quality_report['completeness']])\n",
    "            accuracy_avg = np.mean([item['overall_accuracy'] for item in self.quality_report['accuracy']])\n",
    "            validity_avg = np.mean([item['overall_validity'] for item in self.quality_report['validity']])\n",
    "            \n",
    "            scores = [completeness_avg, accuracy_avg, validity_avg]\n",
    "            \n",
    "            bars = axes[1, 1].bar(metrics, scores, color=['skyblue', 'orange', 'lightgreen'])\n",
    "            axes[1, 1].set_title('Scores M√©dios de Qualidade', fontweight='bold')\n",
    "            axes[1, 1].set_ylabel('Score (%)')\n",
    "            axes[1, 1].set_ylim(0, 100)\n",
    "            \n",
    "            # Adicionar valores nas barras\n",
    "            for bar, score in zip(bars, scores):\n",
    "                height = bar.get_height()\n",
    "                axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                               f'{score:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def generate_summary_report(self):\n",
    "        \"\"\"\n",
    "        Gera um relat√≥rio resumo da an√°lise\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RELAT√ìRIO RESUMO - AN√ÅLISE DE QUALIDADE DE DADOS (DMBOK)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nüìã DATASETS ANALISADOS: {len(self.dataframes)} arquivos CSV\")\n",
    "        print(f\"üìÖ PER√çODO: {min(self.years)} - {max(self.years)}\")\n",
    "        \n",
    "        total_records = sum(len(df) for df in self.dataframes.values())\n",
    "        total_columns = sum(len(df.columns) for df in self.dataframes.values())\n",
    "        print(f\"üìä VOLUME: {total_records:,} registros, {total_columns} colunas (total)\")\n",
    "        \n",
    "        print(f\"\\nüéØ CRIT√âRIOS DMBOK AVALIADOS:\")\n",
    "        \n",
    "        # Completude\n",
    "        if 'completeness' in self.quality_report:\n",
    "            avg_completeness = np.mean([item['overall_completeness'] for item in self.quality_report['completeness']])\n",
    "            print(f\"   ‚úì Completude (Completeness): {avg_completeness:.1f}%\")\n",
    "        \n",
    "        # Precis√£o\n",
    "        if 'accuracy' in self.quality_report:\n",
    "            avg_accuracy = np.mean([item['overall_accuracy'] for item in self.quality_report['accuracy']])\n",
    "            print(f\"   ‚úì Precis√£o (Accuracy): {avg_accuracy:.1f}%\")\n",
    "        \n",
    "        # Consist√™ncia\n",
    "        if 'consistency' in self.quality_report:\n",
    "            structural_consistency = self.quality_report['consistency'][0]['structural_consistency']\n",
    "            print(f\"   ‚úì Consist√™ncia (Consistency): {structural_consistency:.1f}%\")\n",
    "        \n",
    "        # Validade\n",
    "        if 'validity' in self.quality_report:\n",
    "            avg_validity = np.mean([item['overall_validity'] for item in self.quality_report['validity']])\n",
    "            print(f\"   ‚úì Validade (Validity): {avg_validity:.1f}%\")\n",
    "        \n",
    "        # Atualidade\n",
    "        if 'timeliness' in self.quality_report:\n",
    "            timeliness_score = self.quality_report['timeliness']['timeliness_score']\n",
    "            print(f\"   ‚úì Atualidade (Timeliness): {timeliness_score:.1f}%\")\n",
    "        \n",
    "        # Score geral de qualidade\n",
    "        if all(key in self.quality_report for key in ['completeness', 'accuracy', 'validity']):\n",
    "            overall_quality = np.mean([avg_completeness, avg_accuracy, avg_validity])\n",
    "            print(f\"\\nüèÜ SCORE GERAL DE QUALIDADE: {overall_quality:.1f}%\")\n",
    "            \n",
    "            if overall_quality >= 90:\n",
    "                print(\"   üü¢ EXCELENTE - Dados de alta qualidade\")\n",
    "            elif overall_quality >= 75:\n",
    "                print(\"   üü° BOM - Dados de qualidade satisfat√≥ria com pontos de melhoria\")\n",
    "            elif overall_quality >= 60:\n",
    "                print(\"   üü† REGULAR - Dados precisam de melhorias significativas\")\n",
    "            else:\n",
    "                print(\"   üî¥ CR√çTICO - Dados requerem a√ß√£o imediata\")\n",
    "        \n",
    "        print(f\"\\nüìã RECOMENDA√á√ïES:\")\n",
    "        print(f\"   ‚Ä¢ Implementar processos de valida√ß√£o de dados na origem\")\n",
    "        print(f\"   ‚Ä¢ Estabelecer monitoramento cont√≠nuo da qualidade\")\n",
    "        print(f\"   ‚Ä¢ Criar regras de neg√≥cio para campos categ√≥ricos\")\n",
    "        print(f\"   ‚Ä¢ Padronizar formatos e estruturas entre anos\")\n",
    "        print(f\"   ‚Ä¢ Implementar governan√ßa de dados conforme DMBOK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXECU√á√ÉO COM DADOS GERADOS EM 2019,2020,2021,2022 E 2023\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "AN√ÅLISE DE COMPLETUDE (COMPLETENESS)\n",
      "============================================================\n",
      "\n",
      "üìä Ano 2019:\n",
      "  Nome da Vari√°vel: 100.0% completo (0 valores incompletos)\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% completo (0 valores incompletos)\n",
      "  Tipo: 100.0% completo (0 valores incompletos)\n",
      "  Tamanho: 100.0% completo (0 valores incompletos)\n",
      "  Categoria: 100.0% completo (0 valores incompletos)\n",
      "\n",
      "  üìà Completude Geral: 100.0%\n",
      "\n",
      "üìä Ano 2020:\n",
      "  Nome da Vari√°vel: 100.0% completo (0 valores incompletos)\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% completo (0 valores incompletos)\n",
      "  Tipo: 80.0% completo (1 valores incompletos)\n",
      "  Tamanho: 100.0% completo (0 valores incompletos)\n",
      "  Categoria: 100.0% completo (0 valores incompletos)\n",
      "\n",
      "  üìà Completude Geral: 96.0%\n",
      "\n",
      "üìä Ano 2021:\n",
      "  Nome da Vari√°vel: 100.0% completo (0 valores incompletos)\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% completo (0 valores incompletos)\n",
      "  Tipo: 100.0% completo (0 valores incompletos)\n",
      "  Tamanho: 100.0% completo (0 valores incompletos)\n",
      "  Categoria: 100.0% completo (0 valores incompletos)\n",
      "\n",
      "  üìà Completude Geral: 100.0%\n",
      "\n",
      "üìä Ano 2022:\n",
      "  Nome da Vari√°vel: 100.0% completo (0 valores incompletos)\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% completo (0 valores incompletos)\n",
      "  Tipo: 100.0% completo (0 valores incompletos)\n",
      "  Tamanho: 100.0% completo (0 valores incompletos)\n",
      "  Categoria: 100.0% completo (0 valores incompletos)\n",
      "\n",
      "  üìà Completude Geral: 100.0%\n",
      "\n",
      "üìä Ano 2023:\n",
      "  Nome da Vari√°vel: 100.0% completo (0 valores incompletos)\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% completo (0 valores incompletos)\n",
      "  Tipo: 100.0% completo (0 valores incompletos)\n",
      "  Tamanho: 100.0% completo (0 valores incompletos)\n",
      "  Categoria: 100.0% completo (0 valores incompletos)\n",
      "\n",
      "  üìà Completude Geral: 100.0%\n",
      "\n",
      "============================================================\n",
      "AN√ÅLISE DE CONSIST√äNCIA (CONSISTENCY)\n",
      "============================================================\n",
      "\n",
      "üîç Consist√™ncia Estrutural:\n",
      "  üìä Consist√™ncia Estrutural: 100.0%\n",
      "\n",
      "üîç Consist√™ncia de Tipos:\n",
      "  ‚ö†Ô∏è  'Tamanho': Tipos inconsistentes - {2019: 'int64', 2020: 'int64', 2021: 'int64', 2022: 'object', 2023: 'int64'}\n",
      "\n",
      "üîç Consist√™ncia de Categorias:\n",
      "  Nome da Vari√°vel: 100.0% das categorias consistentes\n",
      "  Tipo: 100.0% das categorias consistentes\n",
      "  Tamanho: 75.0% das categorias consistentes\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% das categorias consistentes\n",
      "  Categoria: 100.0% das categorias consistentes\n",
      "\n",
      "============================================================\n",
      "AN√ÅLISE DE PRECIS√ÉO/ACUR√ÅCIA (ACCURACY)\n",
      "============================================================\n",
      "\n",
      "üìä Ano 2019:\n",
      "  Nome da Vari√°vel: 100.0% preciso\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% preciso\n",
      "  Tipo: 100.0% preciso\n",
      "  Tamanho: 100.0% preciso\n",
      "  Categoria: 100.0% preciso\n",
      "\n",
      "  üìà Precis√£o Geral: 100.0%\n",
      "\n",
      "üìä Ano 2020:\n",
      "  Nome da Vari√°vel: 100.0% preciso\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% preciso\n",
      "  Tipo: 100.0% preciso\n",
      "  Tamanho: 100.0% preciso\n",
      "  Categoria: 100.0% preciso\n",
      "\n",
      "  üìà Precis√£o Geral: 100.0%\n",
      "\n",
      "üìä Ano 2021:\n",
      "  Nome da Vari√°vel: 100.0% preciso\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% preciso\n",
      "  Tipo: 100.0% preciso\n",
      "  Tamanho: 100.0% preciso\n",
      "  Categoria: 100.0% preciso\n",
      "\n",
      "  üìà Precis√£o Geral: 100.0%\n",
      "\n",
      "üìä Ano 2022:\n",
      "  Nome da Vari√°vel: 100.0% preciso\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% preciso\n",
      "  Tipo: 100.0% preciso\n",
      "  Tamanho: 80.0% preciso\n",
      "  Categoria: 100.0% preciso\n",
      "\n",
      "  üìà Precis√£o Geral: 96.0%\n",
      "\n",
      "üìä Ano 2023:\n",
      "  Nome da Vari√°vel: 100.0% preciso\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% preciso\n",
      "  Tipo: 100.0% preciso\n",
      "  Tamanho: 100.0% preciso\n",
      "  Categoria: 100.0% preciso\n",
      "\n",
      "  üìà Precis√£o Geral: 100.0%\n",
      "\n",
      "============================================================\n",
      "AN√ÅLISE DE VALIDADE (VALIDITY)\n",
      "============================================================\n",
      "\n",
      "üìä Ano 2019:\n",
      "  Nome da Vari√°vel: 100.0% v√°lido\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% v√°lido\n",
      "  Tipo: 0.0% v√°lido\n",
      "    ‚ö†Ô∏è  5 valores n√£o seguem padr√£o 'N. Descri√ß√£o'\n",
      "  Tamanho: 100.0% v√°lido\n",
      "  Categoria: 60.0% v√°lido\n",
      "    ‚ö†Ô∏è  2 categorias sem numera√ß√£o\n",
      "\n",
      "  üìà Validade Geral: 72.0%\n",
      "\n",
      "üìä Ano 2020:\n",
      "  Nome da Vari√°vel: 100.0% v√°lido\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% v√°lido\n",
      "  Tipo: 0.0% v√°lido\n",
      "    ‚ö†Ô∏è  4 valores n√£o seguem padr√£o 'N. Descri√ß√£o'\n",
      "  Tamanho: 100.0% v√°lido\n",
      "  Categoria: 60.0% v√°lido\n",
      "    ‚ö†Ô∏è  2 categorias sem numera√ß√£o\n",
      "\n",
      "  üìà Validade Geral: 72.0%\n",
      "\n",
      "üìä Ano 2021:\n",
      "  Nome da Vari√°vel: 100.0% v√°lido\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% v√°lido\n",
      "  Tipo: 0.0% v√°lido\n",
      "    ‚ö†Ô∏è  5 valores n√£o seguem padr√£o 'N. Descri√ß√£o'\n",
      "  Tamanho: 100.0% v√°lido\n",
      "  Categoria: 60.0% v√°lido\n",
      "    ‚ö†Ô∏è  2 categorias sem numera√ß√£o\n",
      "\n",
      "  üìà Validade Geral: 72.0%\n",
      "\n",
      "üìä Ano 2022:\n",
      "  Nome da Vari√°vel: 100.0% v√°lido\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% v√°lido\n",
      "  Tipo: 0.0% v√°lido\n",
      "    ‚ö†Ô∏è  5 valores n√£o seguem padr√£o 'N. Descri√ß√£o'\n",
      "  Tamanho: 80.0% v√°lido\n",
      "    ‚ö†Ô∏è  1 valores n√£o num√©ricos\n",
      "  Categoria: 60.0% v√°lido\n",
      "    ‚ö†Ô∏è  2 categorias sem numera√ß√£o\n",
      "\n",
      "  üìà Validade Geral: 68.0%\n",
      "\n",
      "üìä Ano 2023:\n",
      "  Nome da Vari√°vel: 100.0% v√°lido\n",
      "  Descri√ß√£o da Vari√°vel: 100.0% v√°lido\n",
      "  Tipo: 0.0% v√°lido\n",
      "    ‚ö†Ô∏è  5 valores n√£o seguem padr√£o 'N. Descri√ß√£o'\n",
      "  Tamanho: 100.0% v√°lido\n",
      "  Categoria: 60.0% v√°lido\n",
      "    ‚ö†Ô∏è  2 categorias sem numera√ß√£o\n",
      "\n",
      "  üìà Validade Geral: 72.0%\n",
      "\n",
      "============================================================\n",
      "AN√ÅLISE DE ATUALIDADE (TIMELINESS)\n",
      "============================================================\n",
      "üìÖ Anos dispon√≠veis: [2019, 2020, 2021, 2022, 2023]\n",
      "üìä Cobertura Temporal: 100.0%\n",
      "üìà Score de Atualidade: 60.0% (dados mais recentes: 2023)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Fun√ß√£o principal para executar a an√°lise\n",
    "    \"\"\"\n",
    "    print(\"üöÄ INICIANDO AN√ÅLISE DE QUALIDADE DE DADOS - CRIT√âRIOS DMBOK\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Inicializar analisador\n",
    "    analyzer = DMBOKDataQualityAnalyzer()\n",
    "    \n",
    "    # ALTERE AQUI OS CAMINHOS DOS SEUS ARQUIVOS CSV\n",
    "    csv_files = [\n",
    "        'MICRODADOS_CADASTRO_CURSOS_2019.csv', \n",
    "        'MICRODADOS_CADASTRO_CURSOS_2020.csv', \n",
    "        'MICRODADOS_CADASTRO_CURSOS_2021.csv', \n",
    "        'MICRODADOS_CADASTRO_CURSOS_2022.csv', \n",
    "        'MICRODADOS_CADASTRO_CURSOS_2023.csv'  \n",
    "    ]\n",
    "    \n",
    "    # Carregar CSVs\n",
    "    print(\"üìÇ Carregando arquivos CSV...\")\n",
    "    analyzer.load_csvs(csv_files)\n",
    "    \n",
    "    if not analyzer.dataframes:\n",
    "        print(\"‚ùå Nenhum CSV foi carregado. Verifique os caminhos dos arquivos.\")\n",
    "        return\n",
    "    \n",
    "    # Executar an√°lises dos crit√©rios DMBOK\n",
    "    analyzer.analyze_completeness()    # Completude\n",
    "    analyzer.analyze_consistency()     # Consist√™ncia  \n",
    "    analyzer.analyze_accuracy()        # Precis√£o/Acur√°cia\n",
    "    analyzer.analyze_validity()        # Validade\n",
    "    analyzer.analyze_timeliness()      # Atualidade\n",
    "    \n",
    "    # Gerar visualiza√ß√µes\n",
    "    analyzer.generate_visualizations()\n",
    "    \n",
    "    # Gerar relat√≥rio resumo\n",
    "    analyzer.generate_summary_report()\n",
    "    \n",
    "    print(f\"\\n‚úÖ AN√ÅLISE CONCLU√çDA!\")\n",
    "    return analyzer\n",
    "\n",
    "# Executar an√°lise\n",
    "if __name__ == \"__main__\":\n",
    "    # Para executar, descomente a linha abaixo e ajuste os caminhos dos arquivos\n",
    "    # analyzer = main()\n",
    "    \n",
    "    # Exemplo de como carregar dados de exemplo (descomente para testar)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXECU√á√ÉO COM DADOS GERADOS EM 2019,2020,2021,2022 E 2023\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Criar dados de exemplo baseados na estrutura fornecida\n",
    "    example_data = {\n",
    "        'Nome da Vari√°vel': [\n",
    "            'TP_ORGANIZACAO_ACADEMICA',\n",
    "            'TP_CATEGORIA_ADMINISTRATIVA', \n",
    "            'IN_CAPITAL',\n",
    "            'QT_DOCENTE_TOTAL',\n",
    "            'QT_CURSO_TOTAL'\n",
    "        ],\n",
    "        'Descri√ß√£o da Vari√°vel': [\n",
    "            'Tipo de Organiza√ß√£o Acad√™mica da IES',\n",
    "            'Tipo de Categoria Administrativa da IES',\n",
    "            'Indicador se IES est√° na Capital',\n",
    "            'Quantidade Total de Docentes',\n",
    "            'Quantidade Total de Cursos'\n",
    "        ],\n",
    "        'Tipo': ['Num', 'Num', 'Num', 'Num', 'Num'],\n",
    "        'Tamanho': [1, 1, 1, 6, 4],\n",
    "        'Categoria': [\n",
    "            '1. Universidade 2. Centro Universit√°rio 3. Faculdade 4. Instituto Federal de Educa√ß√£o, Ci√™ncia e Tecnologia 5. Centro Federal de Educa√ß√£o Tecnol√≥gica',\n",
    "            '1. P√∫blica Federal 2. P√∫blica Estadual 3. P√∫blica Municipal 4. Privada com fins lucrativos 5. Privada sem fins lucrativos',\n",
    "            '1. Sim 0. N√£o',\n",
    "            'Quantidade',\n",
    "            'Quantidade'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Criar DataFrames de exemplo\n",
    "    analyzer_example = DMBOKDataQualityAnalyzer()\n",
    "    for year in [2019, 2020, 2021, 2022, 2023]:\n",
    "        # Simular pequenas varia√ß√µes nos dados\n",
    "        df_example = pd.DataFrame(example_data.copy())\n",
    "        \n",
    "        # Adicionar alguns valores ausentes e inconsist√™ncias para demonstrar\n",
    "        if year == 2020:\n",
    "            df_example.loc[1, 'Tipo'] = None  # Valor ausente\n",
    "        if year == 2022:\n",
    "            df_example.loc[2, 'Tamanho'] = 'erro'  # Valor inv√°lido\n",
    "        \n",
    "        analyzer_example.dataframes[year] = df_example\n",
    "        analyzer_example.years.append(year)\n",
    "\n",
    "    # Executar an√°lises no exemplo\n",
    "    analyzer_example.analyze_completeness()\n",
    "    analyzer_example.analyze_consistency()\n",
    "    analyzer_example.analyze_accuracy()\n",
    "    analyzer_example.analyze_validity()\n",
    "    analyzer_example.analyze_timeliness()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
